dfvif = vif(datos[,-1])
cat("\u03BB\n")
datos<-read.table("dataworkMASTER.csv",header=TRUE, sep = ";")
dim(datos)
names(datos)
str(datos)
datos = datos[,-1] # Eliminacion de la variable codigo Cod_ID
a=8
b=0
c=4
d=4
elim=c(11+a, 11+b, 21+c, 31+d)
datos=datos[,-elim]
lr = lm(varobj ~., data = datos)
summary(lr)
corr = round(cor(datos[,-1]),2)
nombres <- colnames(datos[,-1])
for (i in 1:(ncol(corr) - 1)) {
for (j in (i + 1):ncol(corr)) {
correlacion <- corr[i, j]
if (correlacion > 0.85) {
cat("Las variables", nombres[i], "y", nombres[j],
"tienen una correlación de", correlacion, "\n")
}
}
}
library(usdm)
dfvif = vif(datos[,-1])
dfvif[dfvif[2] > 10, ]
library(glmnet)
mx = as.matrix(datos[,-1])
my = as.matrix(datos[,1])
valalpha = seq(0, 1, by = 0.1)
best_alpha = NULL
best_lambda = NULL
best_mse = Inf
for (alpha in valalpha) {
cv_fit <- cv.glmnet(mx, my, alpha = alpha)
min_mse <- min(cv_fit$cvm)
lambda_min <- cv_fit$lambda.min
if (min_mse < best_mse) {
best_mse <- min_mse
best_alpha <- alpha
best_lambda <- lambda_min
}
}
data.frame(alpha = best_alpha, lambda = best_lambda, error = best_mse)
best_model <- glmnet(mx, my, alpha = best_alpha, lambda = best_lambda)
cat("Los valores de los hiperparámetros son",  "\u03BB\n", best_model$lambda)
best_model <- glmnet(mx, my, alpha = best_alpha, lambda = best_lambda)
cat("Los valores de los hiperparámetros son  \u03BB\n", best_model$lambda)
best_model <- glmnet(mx, my, alpha = best_alpha, lambda = best_lambda)
cat("Los valores de los hiperparámetros son  \u03BB", best_model$lambda)
best_model <- glmnet(mx, my, alpha = best_alpha, lambda = best_lambda)
cat("Los valores de los hiperparámetros son \u03BB = ", best_model$lambda)
best_model <- glmnet(mx, my, alpha = best_alpha, lambda = best_lambda)
cat("Los valores de los hiperparámetros son \u03BB = ",best_model$lambda)
best_model <- glmnet(mx, my, alpha = best_alpha, lambda = best_lambda)
cat("Los valores de los hiperparámetros son \u03B1 =", alpha,  "\u03BB =",best_model$lambda)
best_model <- glmnet(mx, my, alpha = best_alpha, lambda = best_lambda)
cat("Los valores de los hiperparámetros son \u03B1 =", best_alpha,  "\u03BB =",best_model$lambda)
best_model <- glmnet(mx, my, alpha = best_alpha, lambda = best_lambda)
cat("Los valores optimos de los hiperparámetros son \u03B1 =", best_alpha,  "\u03BB =",best_model$lambda)
best_model <- glmnet(mx, my, alpha = best_alpha, lambda = best_lambda)
cat("Los valores óptimos de los hiperparámetros son \u03B1 =", best_alpha,  "\u03BB =",best_model$lambda)
dim(best_model$beta)
best_model$dev.ratio
sum(datos$var_obj==0)
library(openxlsx)
library(usdm)
library(MASS)
library(dplyr)
library(AER)
library(ggplot2)
datos = read.xlsx("Ejercicio regresión de conteo y gam.xlsx")
head(datos)
sapply(datos, function(x) sum(is.na(x)))
summary(datos)
datos$X13 <- factor(datos$X13, levels = unique(datos$X13))
ggplot(datos, aes(x = var_obj, fill = X13)) +
geom_histogram(binwidth=1) +
facet_grid(X13 ~ ., margins=TRUE, scales="free")
varout = rep(FALSE, ncol(datos)-2)
names(varout) = names(datos)[-c(1,ncol(datos))]
for (i in names(varout)){
varout[i] = length(boxplot(datos[i], plot = FALSE)$out) > 0
}
cat("Las variables", paste(names(varout[varout]), collapse = ", "), "contienen outliers\n")
for (i in names(varout[varout])){
boxplot(datos[i], main = i)
if (all(datos[i]>0)){
datos[i] = log(datos[i])
names(datos)[which(names(datos) == i)] = paste(i , "_trans", sep = "")
}
}
ggplot(datos, aes(x = var_obj)) +
geom_histogram( binwidth = 1)
df1<-data.frame(table(datos$var_obj))
names(df1)<-c("values","Freq")
df1$Tipo<-"Empírica"
df1$Freq<-df1$Freq/sum(df1$Freq)
media<-mean(datos$var_obj)
rango = range(datos$var_obj)[1]:range(datos$var_obj)[2]
df2<-data.frame(values=rango, Freq = dpois(rango,lambda=media))
df2$Tipo<-"Teórica"
df<-rbind(df1,df2)
ggplot(data=df, aes(x=values, y=Freq, fill=Tipo)) +
geom_bar(stat="identity", position=position_dodge()) +
labs(title = "Comparación: Distribución Empírica vs Poisson")
df1 <- data.frame(table(datos$var_obj))
names(df1) <- c("values", "Freq")
df1$Tipo <- "Empírica"
df1$Freq <- df1$Freq / sum(df1$Freq)
media <- mean(datos$var_obj)
varianza <- var(datos$var_obj)
size <- media^2 / (varianza - media)  # size = mu^2 / (sigma^2 - mu)
size <- ifelse(size > 0, size, 1)
rango <- range(datos$var_obj)[1]:range(datos$var_obj)[2]
df2 <- data.frame(values = rango, Freq = dnbinom(rango, size = size, mu = media))
df2$Tipo <- "Teórica"
df <- rbind(df1, df2)
ggplot(data = df, aes(x = values, y = Freq, fill = Tipo)) +
geom_bar(stat = "identity", position = position_dodge()) +
labs(title = "Comparación: Distribución Empírica vs Binomial Negativa") +
theme_minimal()
usdm::vif(datos[,-c(1,14)])
model.poiss <- glm(data=datos,var_obj ~ . , family="poisson")
summary(model.poiss)
model.poiss <- update(model.poiss, . ~ . - X3 - X5 - X6 - X7 - X10 - X12)
summary(model.poiss)
model.poiss <- glm(data=datos,var_obj ~ X1_trans + X2_trans + X4 + X11 , family="poisson")
summary(model.poiss)
model.poiss_full = glm(data = datos, var_obj ~., family = "poisson")
model.poiss_best<-MASS::stepAIC(model.poiss_full, trace = 0)
summary(model.poiss_best)
ggplot(data = datos, aes(x = X11, y = var_obj))+
geom_point() +
labs(title = "X11 VS var_obj")
nd = dim(datos)[1]
rel_var_media = datos %>% group_by(X13) %>%
summarise(media = mean(var_obj), sigma2 = (nd-1)*var(var_obj)/nd)
rel_var_media
ggplot(data = rel_var_media, aes(x = media, y = sigma2)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "purple") +
labs(title= "Relacion media y varianza")
dispersiontest(model.poiss_best)
predicciones <- predict(model.poiss_best, type = "response")
observados <- datos$var_obj
ggplot(data = data.frame(pred = predicciones, obs = observados, X13 = datos$X13),
aes(x = pred, y = obs, color = X13)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "blue") +
labs(title = "Predicciones vs Observados")
cv<-function(x) {sd(x)/abs(mean(x))}
with(datos, tapply(var_obj,X13, function(x) {
sprintf("M (V) (CV) = %1.2f (%1.2f) (%1.2f)", mean(x), var(x), cv(x))
}))
model.bn_full = glm.nb(var_obj~., data = datos)
summary(model.bn_full)
formula = "X1_trans + X2_trans + X4 + X8 + X11"
formula = as.formula(paste("var_obj~", formula))
model.bn_best = glm.nb(formula, data = datos)
summary(model.bn_best)
anova(model.bn_full, model.bn_best)
m = update(model.bn_best, . ~. - X8)
anova(model.bn_best, m)
model.bn_best = m
summary(model.bn_best)
bn = with(model.bn_best, cbind(res.deviance = deviance, df = df.residual,
AIC = aic, p = pchisq(deviance, df.residual, lower.tail=FALSE)))
pois = with(model.poiss_best, cbind(res.deviance = deviance, df = df.residual,
AIC = aic, p = pchisq(deviance, df.residual, lower.tail=FALSE)))
comp = data.frame(rbind(bn,pois))
rownames(comp) = c("bin.neg", "poisson")
comp
X2 <- 2 * (logLik(m) - logLik(model.poiss_best))
X2
pchisq(X2, df = 1, lower.tail=FALSE)
plot(data.frame(datos$var_obj,model.bn_best$resid), main = "var_obj VS residuos",
xlab = "var_obj", ylab = "residuos")
predicciones <- predict(model.bn_best, type = "response")
observados <- datos$var_obj
ggplot(data = data.frame(pred = predicciones, obs = observados, X13 = datos$X13),
aes(x = pred, y = obs, color = X13)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "blue") +
labs(title = "Predicciones vs Observados")
sum(datos$var_obj==0)
sum(round(model.poiss_best$fitted.values)==0)
sum(round(model.bn_best$fitted.values)==0)
data.frame(datos$var_obj, model.bn_best$fitted.values)
data.frame(datos$var_obj, round(model.bn_best$fitted.values))
setwd("~/MasterDSBD/AEM/Entregable AEM_3")
tinytex::reinstall_tinytex()
tinytex::tlmgr_update()
grafico <- ggplot(data = datos, aes(x = datos$X11, y = datos$var_obj)) +
geom_point() +
geom_line(aes(y = model.poly_8$fitted.values), color = "blue") +
labs(title = "Ajuste del modelo",
x = "X11",
y = "var_obj")
library(openxlsx)
library(usdm)
library(MASS)
library(dplyr)
library(AER)
library(ggplot2)
library(gridExtra)
library(mgcv)
library(gamair)
library(splines)
datos = read.xlsx("Ejercicio regresión de conteo y gam.xlsx")
head(datos)
sapply(datos, function(x) sum(is.na(x)))
summary(datos)
datos$X13 <- factor(datos$X13, levels = unique(datos$X13))
ggplot(datos, aes(x = var_obj, fill = X13)) +
geom_histogram(binwidth=1) +
facet_grid(X13 ~ ., margins=TRUE, scales="free")
varout = rep(FALSE, ncol(datos)-2)
names(varout) = names(datos)[-c(1,ncol(datos))]
for (i in names(varout)){
varout[i] = length(boxplot(datos[i], plot = FALSE)$out) > 0
}
cat("Las variables", paste(names(varout[varout]), collapse = ", "), "contienen outliers\n")
for (i in names(varout[varout])){
boxplot(datos[i], main = i)
if (all(datos[i]>0)){
datos[i] = log(datos[i])
names(datos)[which(names(datos) == i)] = paste(i , "_trans", sep = "")
}
}
ggplot(datos, aes(x = var_obj)) +
geom_histogram( binwidth = 1) +
labs(y = "")
df1<-data.frame(table(datos$var_obj))
names(df1)<-c("values","Freq")
df1$Tipo<-"Empírica"
df1$Freq<-df1$Freq/sum(df1$Freq)
media<-mean(datos$var_obj)
rango = range(datos$var_obj)[1]:range(datos$var_obj)[2]
df2<-data.frame(values=rango, Freq = dpois(rango,lambda=media))
df2$Tipo<-"Teórica"
df<-rbind(df1,df2)
(grafico1 = ggplot(data=df, aes(x=values, y=Freq, fill=Tipo)) +
geom_bar(stat="identity", position=position_dodge()) +
labs(title = "Dis. Empírica vs Poisson",
y = "") +
theme(axis.text.x = element_blank()))
xempp <- seq(min(datos$var_obj), max(datos$var_obj), by=0.01)
plot(xempp, ppois(xempp, lambda=media), type="l", col="green", xlab="var_obj",
ylab="ppois(var_obj)")
plot(ecdf(datos$var_obj), col="red",add=TRUE)
df1 <- data.frame(table(datos$var_obj))
names(df1) <- c("values", "Freq")
df1$Tipo <- "Empírica"
df1$Freq <- df1$Freq / sum(df1$Freq)
media <- mean(datos$var_obj)
varianza <- var(datos$var_obj)
size <- media^2 / (varianza - media)  # size = mu^2 / (sigma^2 - mu)
size <- ifelse(size > 0, size, 1)
rango <- range(datos$var_obj)[1]:range(datos$var_obj)[2]
df2 <- data.frame(values = rango, Freq = dnbinom(rango, size = size, mu = media))
df2$Tipo <- "Teórica"
df <- rbind(df1, df2)
(grafico2 =ggplot(data = df, aes(x = values, y = Freq, fill = Tipo)) +
geom_bar(stat = "identity", position = position_dodge()) +
labs(title = "Dis. Empírica vs Binomial Negativa",
y = "") +
theme(axis.text.x = element_blank()))
grid.arrange(grafico1, grafico2, ncol = 2)
usdm::vif(datos[,-c(1,14)])
model.poiss <- glm(data=datos,var_obj ~ . , family="poisson")
summary(model.poiss)
bondad = data.frame(AIC = AIC(model.poiss), dev = model.poiss$deviance)
rownames(bondad)[1] = "pois.full"
model.poiss <- update(model.poiss, . ~ . - X3 - X5 - X6 - X7 - X10 - X12)
summary(model.poiss)
model.poiss <- glm(data=datos,var_obj ~ X1_trans + X2_trans + X4 + X11 , family="poisson")
summary(model.poiss)
model.poiss_full = glm(data = datos, var_obj ~., family = "poisson")
model.poiss_best<-MASS::stepAIC(model.poiss_full, trace = 0)
summary(model.poiss_best)
bondad = rbind(bondad, data.frame(AIC = AIC(model.poiss_best), dev = model.poiss_best$deviance))
rownames(bondad)[nrow(bondad)] = "pois.red"
ggplot(data = datos, aes(x = X11, y = var_obj))+
geom_point() +
labs(title = "X11 VS var_obj")
nd = dim(datos)[1]
rel_var_media = datos %>% group_by(X13) %>%
summarise(media = mean(var_obj), sigma2 = (nd-1)*var(var_obj)/nd)
rel_var_media
ggplot(data = rel_var_media, aes(x = media, y = sigma2)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "purple") +
labs(title= "Relacion media y varianza")
dispersiontest(model.poiss_best)
predicciones <- predict(model.poiss_best, type = "response")
observados <- datos$var_obj
ggplot(data = data.frame(pred = predicciones, obs = observados, X13 = datos$X13),
aes(x = pred, y = obs, color = X13)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "blue") +
labs(title = "Predicciones vs Observados")
model.bn_full = glm.nb(var_obj~., data = datos)
summary(model.bn_full)
formula = "X1_trans + X2_trans + X4 + X8 + X11"
formula = as.formula(paste("var_obj~", formula))
model.bn_best = glm.nb(formula, data = datos)
summary(model.bn_best)
anova(model.bn_full, model.bn_best)
m = update(model.bn_best, . ~. - X8)
anova(model.bn_best, m)
model.bn_best = m
summary(model.bn_best)
plot(data.frame(datos$var_obj,model.bn_best$resid), main = "var_obj VS residuos",
xlab = "var_obj", ylab = "residuos")
predicciones <- predict(model.bn_best, type = "response")
observados <- datos$var_obj
ggplot(data = data.frame(pred = predicciones, obs = observados, X13 = datos$X13),
aes(x = pred, y = obs, color = X13)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "blue") +
labs(title = "Predicciones vs Observados")
bn = with(model.bn_best, cbind(res.deviance = deviance, df = df.residual,
AIC = aic, p = pchisq(deviance, df.residual, lower.tail=FALSE)))
pois = with(model.poiss_best, cbind(res.deviance = deviance, df = df.residual,
AIC = aic, p = pchisq(deviance, df.residual, lower.tail=FALSE)))
comp = data.frame(rbind(bn,pois))
rownames(comp) = c("bin.neg", "poisson")
comp
X2 <- 2 * (logLik(m) - logLik(model.poiss_best))
X2
pchisq(X2, df = 1, lower.tail=FALSE)
sum(datos$var_obj==0)
sum(round(model.poiss_best$fitted.values)==0)
model.gam_fulltp=gam(var_obj~s(X1_trans)+s(X2_trans)+s(X3)+s(X4)+s(X5)+s(X6)+s(X7)+s(X8)
+s(X9)+s(X10)+s(X11)+s(X12),
family=poisson,data=datos)
summary(model.gam_fulltp)
bondad = rbind(bondad, data.frame(AIC = AIC(model.gam_fulltp), dev = model.gam_fulltp$deviance))
rownames(bondad)[nrow(bondad)] = "gam.full"
bondad
concurvity(model.gam_fulltp)
model.gam=gam(var_obj~s(X1_trans)+s(X2_trans)+s(X3)+s(X5)+s(X6)+s(X8)+s(X9)+
s(X10)+s(X11)+s(X12),
family=poisson,data=datos)
summary(model.gam)
AIC(model.gam)
concurvity(model.gam)
model.gam=gam(var_obj~s(X1_trans)+s(X2_trans)+s(X3)+s(X6)+s(X8)
+s(X9)++s(X11)+s(X12),
family=poisson,data=datos)
summary(model.gam)
AIC(model.gam)
concurvity(model.gam)
model.gam=gam(var_obj~s(X2_trans)+s(X3)+s(X8)+s(X9)+s(X11)+s(X12),
family=poisson,data=datos)
summary(model.gam)
AIC(model.gam)
concurvity(model.gam)
model.gam_X11tp=gam(var_obj~s(X11), family=poisson,data=datos)
summary(model.gam_X11tp)
bondad = rbind(bondad, data.frame(AIC = AIC(model.gam_X11tp), dev = model.gam_X11tp$deviance))
rownames(bondad)[nrow(bondad)] = "gam.X11tp"
bondad
resultado_anova = anova.gam(model.gam_fulltp, model.gam_X11tp)
diff_dev <- resultado_anova$Deviance[2]
diff_df <- abs(resultado_anova$Df[2])
pchisq(diff_dev, df = diff_df, lower.tail = FALSE)
ggplot(data = datos, aes(x = datos$X11, y = datos$var_obj)) +
geom_point() +
geom_line(aes(y = model.gam_X11tp$fitted.values), color = "blue") +
labs(title = "Ajuste del modelo",
x = "X11",
y = "var_obj")
model.gam=gam(var_obj~s(X11,by=X13),family=poisson,data=datos)
summary(model.gam)
data.frame(AIC = AIC(model.gam), dev = model.gam$deviance)
model.gam_X11ts=gam(var_obj~s(X11,bs="ts"),family=poisson,data=datos)
summary(model.gam_X11ts)
bondad = rbind(bondad, data.frame(AIC = AIC(model.gam_X11ts), dev = model.gam_X11ts$deviance))
rownames(bondad)[nrow(bondad)] = "gam.X11ts"
bondad
model.gam_X11cr=gam(var_obj~s(X11,bs="cr"),family=poisson,data=datos)
summary(model.gam_X11cr)
bondad = rbind(bondad, data.frame(AIC = AIC(model.gam_X11cr), dev = model.gam_X11cr$deviance))
rownames(bondad)[nrow(bondad)] = "gam.X11cr"
bondad
grados <- 1:10
mejor_grado <- NULL
mejor_modelo <- NULL
mejor_anova_p <- 1
modelo_anterior <- lm(var_obj ~ poly(X11, 1, raw = TRUE), data = datos)
for (g in grados[-1]) {
modelo_actual <- lm(var_obj ~ poly(X11, g, raw = TRUE), data = datos)
anova_resultado <- anova(modelo_anterior, modelo_actual)
p_valor <- anova_resultado$`Pr(>F)`[2]
cat("Grado:", g, " ---- p-valor:", p_valor, "\n")
if (p_valor < 0.05) {
mejor_grado <- g
mejor_modelo <- modelo_actual
mejor_anova_p <- p_valor
modelo_anterior <- modelo_actual
} else {
cat("No hay diferencias significativas entre grado", g, "y grado", g-1, "detenemos la búsqueda.\n")
break
}
}
cat("\nMejor grado:", mejor_grado, "con p-valor:", mejor_anova_p, "\n")
summary(mejor_modelo)
model.poly_8 = mejor_modelo
bondad = rbind(bondad, data.frame(AIC = AIC(model.poly_8), dev = NA))
rownames(bondad)[nrow(bondad)] = "poly"
bondad
grafico <- ggplot(data = datos, aes(x = datos$X11, y = datos$var_obj)) +
geom_point() +
geom_line(aes(y = model.poly_8$fitted.values), color = "blue") +
labs(title = "Ajuste del modelo",
x = "X11",
y = "var_obj")
# Mostrar el gráfico
print(grafico)
# Guardar el gráfico como un archivo PNG
ggsave("model.poly_8.png", plot = grafico, width = 8, height = 6, dpi = 300)
set.seed(12345)
ind = sample(1:nrow(datos), size = 2/3 * nrow(datos))
train = datos[ind, ]
test = datos[-ind, ]
final_model = lm(var_obj~poly(X11, 8, raw = T), data = train)
pred = predict(final_model, newdata = data.frame(X11 = test$X11))
grafico =ggplot(data = test, aes(x = X11, y = var_obj)) +
geom_point() +
geom_line(aes(y = pred), color = "blue") +
labs(title = "Ajuste del modelo en el conjunto test",
x = "X11",
y = "var_obj")
ggsave("model.poly_8_test.png", plot = grafico, width = 8, height = 6, dpi = 300)
set.seed(12345)
ind = sample(1:nrow(datos), size = 2/3 * nrow(datos))
train = datos[ind, ]
test = datos[-ind, ]
final_model = lm(var_obj~poly(X11, 8, raw = T), data = train)
pred = predict(final_model, newdata = data.frame(X11 = test$X11))
grafico = ggplot(data = test, aes(x = X11, y = var_obj)) +
geom_point() +
geom_line(aes(y = pred), color = "blue") +
labs(title = "Ajuste del modelo en el conjunto test",
x = "X11",
y = "var_obj")
ggsave("ajuste_modelo.png", plot = grafico, width = 6, height = 4, dpi = 300)
set.seed(12345)
ind = sample(1:nrow(datos), size = 2/3 * nrow(datos))
train = datos[ind, ]
test = datos[-ind, ]
final_model = lm(var_obj~poly(X11, 8, raw = T), data = train)
pred = predict(final_model, newdata = data.frame(X11 = test$X11))
grafico = ggplot(data = test, aes(x = X11, y = var_obj)) +
geom_point() +
geom_line(aes(y = pred), color = "blue") +
labs(title = "Ajuste del modelo en el conjunto test",
x = "X11",
y = "var_obj")
ggsave("model.poly_8_test.png", plot = grafico, width = 6, height = 4, dpi = 300)
grafico = ggplot(data = datos, aes(x = datos$X11, y = datos$var_obj)) +
geom_point() +
geom_line(aes(y = model.poly_8$fitted.values), color = "blue") +
labs(title = "Ajuste del modelo",
x = "X11",
y = "var_obj")
ggsave("model.poly_8.png", plot = grafico, width = 6, height = 4, dpi = 300)
grafico = ggplot(data = datos, aes(x = datos$X11, y = datos$var_obj)) +
geom_point() +
geom_line(aes(y = model.poly_8$fitted.values), color = "blue") +
labs(title = "Ajuste del modelo",
x = "X11",
y = "var_obj")
ggsave("model.poly_8_test.png", plot = grafico, width = 4, height = 2, dpi = 300)
set.seed(12345)
ind = sample(1:nrow(datos), size = 2/3 * nrow(datos))
train = datos[ind, ]
test = datos[-ind, ]
final_model = lm(var_obj~poly(X11, 8, raw = T), data = train)
pred = predict(final_model, newdata = data.frame(X11 = test$X11))
grafico = ggplot(data = test, aes(x = X11, y = var_obj)) +
geom_point() +
geom_line(aes(y = pred), color = "blue") +
labs(title = "Ajuste del modelo en el conjunto test",
x = "X11",
y = "var_obj")
ggsave("model.poly_8_test.png", plot = grafico, width = 4, height = 2, dpi = 300)
grafico = ggplot(data = datos, aes(x = datos$X11, y = datos$var_obj)) +
geom_point() +
geom_line(aes(y = model.poly_8$fitted.values), color = "blue") +
labs(title = "Ajuste del modelo",
x = "X11",
y = "var_obj")
ggsave("model.poly_8.png", plot = grafico, width = 4, height = 2, dpi = 300)
set.seed(12345)
ind = sample(1:nrow(datos), size = 2/3 * nrow(datos))
train = datos[ind, ]
test = datos[-ind, ]
final_model = lm(var_obj~poly(X11, 8, raw = T), data = train)
pred = predict(final_model, newdata = data.frame(X11 = test$X11))
grafico = ggplot(data = test, aes(x = X11, y = var_obj)) +
geom_point() +
geom_line(aes(y = pred), color = "blue") +
labs(title = "Ajuste del modelo en el conjunto test",
x = "X11",
y = "var_obj")
ggsave("model.poly_8_test.png", plot = grafico, width = 4, height = 2, dpi = 300)
